{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:dd1477de5ecfabafd030069047072104409bfa8f86b0618930d6b5e89ff60714"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Intro to Machine Learning\n",
      "### DesertPy\n",
      "### 24 September 2014\n",
      "### Sarah Braden"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "##What is Machine Learning?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Python and Machine Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Examples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# What is Machine Learning?\n",
      "\n",
      "<img src=\"http://sentdex.com/wp-content/uploads/2013/10/machineLearning.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Why do you use Machine Learning?\n",
      "### To make predictions and decisions\n",
      "\n",
      "<img src=\"http://3.bp.blogspot.com/-TynYj7aCmak/UKtmuVx7Q9I/AAAAAAAABcM/FjIsS6-TTVQ/s1600/statistical_based_decision_making.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## When do you use it?\n",
      "### When the going gets tough"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Who uses it?\n",
      "- Spam filters / Fraud detection\n",
      "- Sentiment Analysis\n",
      "- Computer Vision\n",
      "- Speech and Handwriting Recognition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## What do you need?\n",
      "- A Problem!\n",
      "- Data\n",
      "  - Features\n",
      "  - Labels (for supervised learning)\n",
      "- Programming Skillz\n",
      "- Patience / Stubborness / Math "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Are there different kinds of Machine Learning?\n",
      "- Supervised Learning\n",
      "    - Data has both features and labels\n",
      "    - Classification (label is a class)\n",
      "    - Regression (label is a continuous value)\n",
      "- Unsupervised Learning\n",
      "    - Data only has features\n",
      "    - Clustering\n",
      "    - Use clustering and then classification together!\n",
      "- Feature Engineering\n",
      "- Many other things"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "I'm still interested. Tell me more..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Python and Machine Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Fire up scikit-learn!\n",
      "![](http://scipy-lectures.github.io/_images/scikit-learn-logo.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## scikit-learn dependencies\n",
      "- Python (>= 2.6 or >= 3.3)\n",
      "- NumPy (>= 1.6.1)\n",
      "- SciPy (>= 0.9)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<code>pip install numpy scipy scikit-learn</code>\n",
      "\n",
      "<img src=\"http://i.imgur.com/Gktl45B.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Why is scikit-learn awesome?\n",
      "- Out-of-the-box Models\n",
      "- Model Selection (important!)\n",
      "- Data Preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## More than just scikit-learn\n",
      "- PyMC (Bayesian modeling)\n",
      "- Shogun (Support Vector Machines)\n",
      "- Theano (Deep Learning)\n",
      "\n",
      "[Other Python Machine Learning Libraries](http://www.cbinsights.com/blog/python-tools-machine-learning/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Example of a Spam Filter using Naive Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Dataset\n",
      "* Text files of emails from [Machine Learning in Action published by Manning](http://manning.com/pharrington)\n",
      "* <code> unzip email.zip </code>\n",
      "* Small dataset of ham and spam"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Data Preprocessing\n",
      "Making word vectors before we use Naive Bayes to classify the word vectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import numpy as np\n",
      "from glob import glob\n",
      "\n",
      "# Use regular expressions to split up the sentence on anything that isn't a word or a number\n",
      "regEx = re.compile('\\\\W*')\n",
      "\n",
      "email_text = open('email/ham/1.txt').read()\n",
      "# words sorta equal tokens\n",
      "list_of_tokens = regEx.split(email_text)\n",
      "list_of_tokens"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "['Hi',\n",
        " 'Peter',\n",
        " 'With',\n",
        " 'Jose',\n",
        " 'out',\n",
        " 'of',\n",
        " 'town',\n",
        " 'do',\n",
        " 'you',\n",
        " 'want',\n",
        " 'to',\n",
        " 'meet',\n",
        " 'once',\n",
        " 'in',\n",
        " 'a',\n",
        " 'while',\n",
        " 'to',\n",
        " 'keep',\n",
        " 'things',\n",
        " 'going',\n",
        " 'and',\n",
        " 'do',\n",
        " 'some',\n",
        " 'interesting',\n",
        " 'stuff',\n",
        " 'Let',\n",
        " 'me',\n",
        " 'know',\n",
        " 'Eugene']"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_text(email_filename):\n",
      "    \"\"\"converts all tokens to lowercase and removes tokens < 2 characters long\n",
      "    \"\"\"\n",
      "    email_text = open(email_filename).read()\n",
      "    tokens = re.split('\\\\W*', email_text)\n",
      "    return [token.lower() for token in tokens if len(token) > 2]\n",
      "\n",
      "\n",
      "def get_all_text(email_type):\n",
      "    files = glob('email/' + email_type + '/*.txt')\n",
      "    return [parse_text(file) for file in files]"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_vocab_list(dataSet):\n",
      "    vocabSet = set([])  #create empty set\n",
      "    for document in dataSet:\n",
      "        vocabSet = vocabSet | set(document) #union of the two sets\n",
      "    return list(vocabSet)\n",
      "\n",
      "def bag_of_words(vocab_list, input_words):\n",
      "    returnVec = [0]*len(vocab_list)\n",
      "    for word in input_words:\n",
      "        if word in vocab_list:\n",
      "            returnVec[vocab_list.index(word)] += 1\n",
      "    return returnVec"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "email_types = ['ham', 'spam']\n",
      "\n",
      "ham = get_all_text('ham')\n",
      "spam = get_all_text('spam')      \n",
      "\n",
      "all_documents = ham + spam\n",
      "all_labels = ['ham'] * 25 + ['spam'] * 25\n",
      "\n",
      "vocab_list = create_vocab_list(all_documents)  #create vocabulary\n",
      "\n",
      "# Convert the documents into word vectors\n",
      "features = [bag_of_words(vocab_list, document) for document in all_documents]\n",
      "\n",
      "print np.array(features).shape\n",
      "print np.array(all_labels).shape"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50, 692)\n",
        "(50,)\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## We have features and labels!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cross validation\n",
      "from sklearn import cross_validation\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
      "    np.array(features), np.array(all_labels), test_size=0.3, random_state=0)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Training set:\", X_train.shape, y_train.shape\n",
      "print \"Test set:\", X_test.shape, y_test.shape"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training set: (35, 692) (35,)\n",
        "Test set: (15, 692) (15,)\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "classifier = GaussianNB()\n",
      "classifier.fit(X_train, y_train)\n",
      "y_pred = classifier.predict(X_test)\n",
      "print \"Number of mislabeled points : %d\" % (y_test != y_pred).sum()\n",
      "print \"Score:\", classifier.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of mislabeled points : 1\n",
        "Score: 0.933333333333\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        ham       0.86      1.00      0.92         6\n",
        "       spam       1.00      0.89      0.94         9\n",
        "\n",
        "avg / total       0.94      0.93      0.93        15\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Example of Unsupervised Learning using K-means Clustering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Distance between data points\n",
      "- Using the Euclidean distance metric"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "[Iris Flower Data Set](http://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
      "- The data set consists of 50 samples from each of three species of Iris\n",
      "    - Iris setosa\n",
      "    - Iris virginica\n",
      "    - Iris versicolor\n",
      "- Four features were measured from each sample: \n",
      "    - the length of the sepals \n",
      "    - the width of the sepals\n",
      "    - the length of the petals\n",
      "    - the width of the petals\n",
      "\n",
      "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/220px-Iris_versicolor_3.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cluster, datasets\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "X_iris = iris.data  # features\n",
      "y_iris = iris.target  # labels"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_means = cluster.KMeans(n_clusters=3)\n",
      "k_means.fit(X_iris)\n",
      "\n",
      "print(k_means.labels_[::10])\n",
      "print(y_iris[::10])"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 1 1 1 1 2 2 2 2 2 0 0 0 0 0]\n",
        "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Learn More!\n",
      "- [MIT OpenCourseware](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)\n",
      "- [Kaggle Blog: Getting Started with Python for Data Science](https://www.kaggle.com/wiki/GettingStartedWithPythonForDataScience)\n",
      "- [Scikit-learn](http://scikit-learn.org/stable/)\n",
      "- [Python Natural Language Toolkit (NLTK)](http://www.nltk.org/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Thanks!\n",
      "\n",
      "Sarah Braden\n",
      "\n",
      "[twitter.com/ifmoonwascookie](https://twitter.com/ifmoonwascookie)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}