{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to talk to your computer\n",
    "## An introduction into Automatic Speech Recognition (ASR) in Python\n",
    "\n",
    "Sarah Braden\n",
    "\n",
    "Twitter: @ifmoonwascookie\n",
    "\n",
    "28 October 2015\n",
    "\n",
    "DesertPy Meetup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fun stuff people do with ASR\n",
    "* voice control of your computer\n",
    "* intelligen cars/homes\n",
    "* speech transcription\n",
    "* closed captioning\n",
    "* speech translation\n",
    "* voice search\n",
    "* language learning\n",
    "* language testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# What is CMUSphinx?\n",
    "[CMU Sphinx](http://cmusphinx.sourceforge.net/)\n",
    "\n",
    "* Devloped by Carnegie Mellon University\n",
    "* Speaker-independent continuous speech recognition engine\n",
    "* BSD-like license which allows commercial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Support for several languages:\n",
    "    * US English\n",
    "    * UK English\n",
    "    * European French\n",
    "    * Mandarin\n",
    "    * German\n",
    "    * Dutch\n",
    "    * Russian\n",
    "* Ability to build a models for other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is CMUSphinx?\n",
    "\n",
    "* Designed specifically for low-resource platforms\n",
    "* Multiple tools\n",
    "    * Pocketsphinx - recognizer library written in C\n",
    "    * Sphinxtrain - acoustic model training tools\n",
    "    * Sphinxbase - support library required by Pocketsphinx and Sphinxtrain\n",
    "    * Sphinx4 - adjustable, modifiable recognizer written in Java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's be real\n",
    "\n",
    "* No, this is not going to be as awesome as Google or Siri right out of the box\n",
    "* The word error rate is going to vary depending on your language and audio quality\n",
    "* It takes a while to figure out the details, but it is better than starting from scratch\n",
    "* You can train it to \"fit\" your voice and get more accurate results with sphinxtrain (http://cmusphinx.sourceforge.net/wiki/tutorialam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Install version 5prealpha from source\n",
    "\n",
    "Install both [sphinxbase-5prealapha](http://sourceforge.net/projects/cmusphinx/files/sphinxbase/5prealpha/) and [pocketsphinx-5prealpha](http://sourceforge.net/projects/cmusphinx/files/pocketsphinx/5prealpha/)\n",
    "\n",
    "* Compiling from the code on source forge is the best option. \n",
    "* Despite the name, 5prealpha is the recommended \"stable\" release. \n",
    "* Make sure to install both pocketsphinx-5prealpha and sphinxbase-5prealpha. \n",
    "* Follow the instructions in the README included in the download. \n",
    "* It takes a while to install and compile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The command should work if you have CMUSphinx installed correctly. This command listens to the mic input and attempts to print to screen what it hears.\n",
    "\n",
    "```bash\n",
    "$ pocketsphinx_continuous -inmic yes\n",
    "```\n",
    "\n",
    "Another command which takes an input .wav file:\n",
    "\n",
    "```bash\n",
    "$ pocketsphinx_continuous -infile test_mono_16k.wav\n",
    "```\n",
    "\n",
    "Get the full list of options by typing:\n",
    "\n",
    "```bash\n",
    "$ pocketsphinx_continuous\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Useful Tips\n",
    "\n",
    "* pocketsphinx requires mono recordings. Don't forget to make sure your audio matches the correct sample rate that the acoustic model expects.\n",
    "\n",
    "* an easy way to create a test audio file is to use Audacity (http://audacityteam.org/) and set the sample rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pocketsphinx\n",
    "\n",
    "base_dir = '/usr/local/share/pocketsphinx/model/en-us'\n",
    "\n",
    "# acoustic model\n",
    "hidden_markov_model = path.join(base_dir, 'hub4wsj_sc_8k')\n",
    "\n",
    "# language model\n",
    "language_model = path.join(base_dir, 'cmusphinx-5.0-en-us.lm')\n",
    "\n",
    "# dictionary\n",
    "dictionary = path.join(base_dir, 'cmudict-en-us.dict')\n",
    "\n",
    "# Create a decoder with certain model\n",
    "config = pocketsphinx.Decoder.default_config()\n",
    "config.set_string('-hmm', hidden_markov_model)\n",
    "config.set_string('-dict', dictionary)\n",
    "config.set_string('-lm', language_model)\n",
    "config.set_float('-samprate', 8000.0)\n",
    "\n",
    "decoder = pocketsphinx.Decoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'the_customer_is_eating_an_apple.wav'\n",
    "\n",
    "with open(filename, 'rb') as wav:\n",
    "    decoder.decode_raw(wav)\n",
    "\n",
    "result = decoder.hyp().hypstr\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8k audio\n",
    "\n",
    "8k audio is what telephones and voip use.\n",
    "\n",
    "The result printed to screen is: \"it directed eating an apple\"\n",
    "\n",
    "## 16k audio \n",
    "\n",
    "16k audio is the default sample rate for CMU Sphinx.\n",
    "\n",
    "hidden_markov_model = path.join(base_dir, 'en-us')\n",
    "\n",
    "The result printed to screen is: \"the customer is eating an apple\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What does the language model do?\n",
    "\n",
    "* Restricts the word search by defining which word could follow previously recognized words\n",
    "* Contains statistics of word sequences called N-grams\n",
    "* starts with a header, introduced by the keyword \\data\\, listing the number of N-grams of each length\n",
    "<code>\n",
    "ngram 1=19794\n",
    "ngram 2=1377200\n",
    "ngram 3=3178194\n",
    "</code>\n",
    "Each N-gram line starts with the logarithm (base 10) of conditional probability p of that N-gram, followed by the words making up the N-gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The file looks like a lot of this:\n",
    "\n",
    "-1.4612 zero one two \n",
    "\n",
    "-2.0386 zero one three \n",
    "\n",
    "-1.6586 zurich switzerland hello\n",
    "\n",
    "-0.4470 zoom in on \n",
    "\n",
    "-2.5581 zoom in please"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What does the dictionary do?\n",
    "\n",
    "* The dictionary I used above has 133425 pronunciations of words!\n",
    "* Contains a mapping from words to phones \n",
    "* What if you have an accent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The file looks like a lot of this:\n",
    "\n",
    "abbreviate AH B R IY V IY EY T\n",
    "\n",
    "abbreviated AH B R IY V IY EY T AH D\n",
    "\n",
    "abbreviated(2) AH B R IY V IY EY T IH D\n",
    "\n",
    "zoological Z UW L AA JH IH K AH L\n",
    "\n",
    "zoologist Z OW AA L AH JH AH S T\n",
    "\n",
    "zoologists Z OW AA L AH JH AH S T S\n",
    "\n",
    "zoologists(2) Z OW AA L AH JH AH S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grammars and Keywords\n",
    "\n",
    "* Java Speech Grammar Format (JSGF)\n",
    "* Keyword Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#JSGF V1.0;\n",
    "\n",
    "grammar example;\n",
    "\n",
    "public <s> = <simple>;\n",
    "\n",
    "<simple> = up\n",
    "     | down\n",
    "     | left\n",
    "     | right\n",
    "     ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using a grammar file\n",
    "\n",
    "Instead of setting the language model, you set the grammar file in the configuration of your decoder.\n",
    "\n",
    "config.set_string('-jsgf', grammar_file.jsgf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setting a keyphrase or multiple keyphrases\n",
    "Instead of setting the language model, you set the keyphrase or keyphrase file in the configuration of your decoder.\n",
    "\n",
    "config.set_string('-keyphrase', 'bananas')\n",
    "\n",
    "or\n",
    "\n",
    "config.set_string('-kws', keyphrases.txt)\n",
    "\n",
    "keyphrases.txt is a file with keyphrases to spot, one per line."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
